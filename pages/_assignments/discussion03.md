---
layout: assignment
title: "Discussion Board Week 3"
abbreviation: Discussion 3
due_date: 2024-07-03
ordering: 1
draft: 0
---

Please respond to this week's discussion prompt on Canvas. Remember that these online discussions are a form of collaborative sense-making to understand, critique, and interrogate this week's readings. Please make your **initial post by Wednesday** so your peers have time to read and respond to your post. You should engage with and **respond to your peers by Friday**.

We encourage you to engage with as many peers as you’re able to, and challenge you to do so deeply and meaningfully. The goal is to have a conversation, not to meet a requirement. Your replies to each other should build on each other's ideas and draw from the readings and your experiences, and should be done in a respectful tone even if you disagree.

<!-- 
Building on last week's conversations around politics, ecologies, and technology, this week we're unpacking the idea of intentionality a bit more. We often hear the term 'unintended consequences' or even ourselves use 'it wasn't my intention' when attempting to apologize. From Parvin and Pollock we learn that people often dismiss potentials of harm (what they'll end up calling 'unintended consequences') for being too difficult, out of reach, out of scope, or too messy to have been dealt with during a product's design. When technology does harm people, it’s viewed as side-effect that we are not responsible for, since it wasn't our intention to cause harm. However, a lot of times these issues were un-anticipated or actively ignored/dismissed when they could have been anticipated, but labeling them as 'unintended' allows us to dismiss accountability. Brashear builds on these ideas by juxtaposing various perspectives on human biotechnologies that seek to 'advance' humanity— noting how these technologies can be used for empowerment while also remaining inaccessible, and at times even undesirable, to those they're meant to be for.

For **your initial response**, reflect on the readings this week:
- What are some of the different goals of these technologies?
- What are they being designed to do?
- What are some of the values, assumptions, and politics present in these technologies and in the ecologies surrounding them? 
- In what ways do they feel ethical or unethical?
- In what ways are the technology designers paying attention to their user’s needs?
- In what ways are they failing to do so?

As you **respond to your peers**, consider:
- What are some ways to **better anticipate** the effects of the tools and technologies we develop?
- What actions can we take **as individuals** to better design tools and technologies? 
- What policies and practices should we implement **as a field and society**?
- How can/should we balance accidental and unintended harm(s) with **responsibility and accountability**?
 -->